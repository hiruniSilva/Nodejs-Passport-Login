{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7dwOLWdWZnI/0Hwph4A7R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiruniSilva/Nodejs-Passport-Login/blob/master/06022022_container_damage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDG_5bNFOwvO",
        "outputId": "191322bb-0fec-4ccc-c38a-432b23c39f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/FYP/DATASET/dataset.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDQ-RNbCRAZ5",
        "outputId": "99371898-d0a8-43f8-8e6f-7f974dedf828"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/FYP/DATASET/dataset.zip\n",
            " extracting: /content/dataset/class-names.txt  \n",
            "  inflating: /content/dataset/generate_tfrecord.py  \n",
            "  inflating: /content/dataset/labelmap.pbtxt  \n",
            "   creating: /content/dataset/test/\n",
            "  inflating: /content/dataset/test/IMG-20230119-WA0008.jpg  \n",
            "  inflating: /content/dataset/test/IMG-20230119-WA0008.xml  \n",
            "  inflating: /content/dataset/test/IMG-20230119-WA0010.jpg  \n",
            "  inflating: /content/dataset/test/IMG-20230119-WA0010.xml  \n",
            "  inflating: /content/dataset/test/IMG-20230125-WA0000.jpg  \n",
            "  inflating: /content/dataset/test/IMG-20230125-WA0000.xml  \n",
            "  inflating: /content/dataset/test/IMG-20230125-WA0001.jpg  \n",
            "  inflating: /content/dataset/test/IMG-20230125-WA0001.xml  \n",
            "  inflating: /content/dataset/test/IMG-20230204-WA0010.jpg  \n",
            "  inflating: /content/dataset/test/IMG-20230204-WA0010.xml  \n",
            "  inflating: /content/dataset/test/IMG-20230204-WA0011.jpg  \n",
            "  inflating: /content/dataset/test/IMG-20230204-WA0011.xml  \n",
            "  inflating: /content/dataset/test/IMG-20230204-WA0012.jpg  \n",
            "  inflating: /content/dataset/test/IMG-20230204-WA0012.xml  \n",
            "  inflating: /content/dataset/test/IMG-20230204-WA0013.jpg  \n",
            "  inflating: /content/dataset/test/IMG-20230204-WA0013.xml  \n",
            "  inflating: /content/dataset/test/Rust_1.jpg  \n",
            "  inflating: /content/dataset/test/Rust_1.xml  \n",
            "  inflating: /content/dataset/test/Rust_2.jpg  \n",
            "  inflating: /content/dataset/test/Rust_2.xml  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-13-55-23_6012fa4d4ddec268fc5c7112cbb265e7.jpg  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-14-17-76_6012fa4d4ddec268fc5c7112cbb265e7.xml  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-21-27-66_6012fa4d4ddec268fc5c7112cbb265e7.jpg  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-21-27-66_6012fa4d4ddec268fc5c7112cbb265e7.xml  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-21-45-92_6012fa4d4ddec268fc5c7112cbb265e7.jpg  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-21-45-92_6012fa4d4ddec268fc5c7112cbb265e7.xml  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-22-04-19_6012fa4d4ddec268fc5c7112cbb265e7.jpg  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-22-04-19_6012fa4d4ddec268fc5c7112cbb265e7.xml  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-44-24-59_6012fa4d4ddec268fc5c7112cbb265e7.jpg  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-44-24-59_6012fa4d4ddec268fc5c7112cbb265e7.xml  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-44-38-40_6012fa4d4ddec268fc5c7112cbb265e7.jpg  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-44-38-40_6012fa4d4ddec268fc5c7112cbb265e7.xml  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-44-52-78_6012fa4d4ddec268fc5c7112cbb265e7.jpg  \n",
            "  inflating: /content/dataset/test/Screenshot_2023-01-16-12-44-52-78_6012fa4d4ddec268fc5c7112cbb265e7.xml  \n",
            "  inflating: /content/dataset/test/Screenshot_20230117-025529_WhatsApp.jpg  \n",
            "  inflating: /content/dataset/test/Screenshot_20230117-025529_WhatsApp.xml  \n",
            "  inflating: /content/dataset/test/ZCSU6739209 with roof hole IMG-20220723-WA0039.jpg  \n",
            "  inflating: /content/dataset/test/ZCSU6739209 with roof hole IMG-20220723-WA0039.xml  \n",
            "  inflating: /content/dataset/test/ZCSU6739209 with roof hole IMG-20220723-WA0045.jpg  \n",
            "  inflating: /content/dataset/test/ZCSU6739209 with roof hole IMG-20220723-WA0045.xml  \n",
            "  inflating: /content/dataset/test/ZCSU6739209 with roof hole IMG-20220723-WA0046.jpg  \n",
            "  inflating: /content/dataset/test/ZCSU6739209 with roof hole IMG-20220723-WA0046.xml  \n",
            "   creating: /content/dataset/train/\n",
            "  inflating: /content/dataset/train/05.jpg  \n",
            "  inflating: /content/dataset/train/05.xml  \n",
            "  inflating: /content/dataset/train/06.jpg  \n",
            "  inflating: /content/dataset/train/06.xml  \n",
            "  inflating: /content/dataset/train/1673699823754.jpg  \n",
            "  inflating: /content/dataset/train/1673699823754.xml  \n",
            "  inflating: /content/dataset/train/1673699823763.jpg  \n",
            "  inflating: /content/dataset/train/1673699823763.xml  \n",
            "  inflating: /content/dataset/train/1673699823775.jpg  \n",
            "  inflating: /content/dataset/train/1673699823775.xml  \n",
            "  inflating: /content/dataset/train/1673699823788.jpg  \n",
            "  inflating: /content/dataset/train/1673699823788.xml  \n",
            "  inflating: /content/dataset/train/BULGE OUT DENTS IMG-20211118-WA0028.jpg  \n",
            "  inflating: /content/dataset/train/BULGE OUT DENTS IMG-20211118-WA0028.xml  \n",
            "  inflating: /content/dataset/train/BULGE OUT DENTS IMG-20211118-WA0031.jpg  \n",
            "  inflating: /content/dataset/train/BULGE OUT DENTS IMG-20211118-WA0031.xml  \n",
            "  inflating: /content/dataset/train/BULGE OUT IMG-20220708-WA0017.jpg  \n",
            "  inflating: /content/dataset/train/BULGE OUT IMG-20220708-WA0017.xml  \n",
            "  inflating: /content/dataset/train/BULGE OUT IMG-20220708-WA0018.jpg  \n",
            "  inflating: /content/dataset/train/BULGE OUT IMG-20220708-WA0018.xml  \n",
            "  inflating: /content/dataset/train/BULGE OUT IMG-20220708-WA0019.jpg  \n",
            "  inflating: /content/dataset/train/BULGE OUT IMG-20220708-WA0019.xml  \n",
            "  inflating: /content/dataset/train/BULGE OUT IMG-20220708-WA0020.jpg  \n",
            "  inflating: /content/dataset/train/BULGE OUT IMG-20220708-WA0020.xml  \n",
            "  inflating: /content/dataset/train/Bulged_1.jpg  \n",
            "  inflating: /content/dataset/train/Bulged_1.xml  \n",
            "  inflating: /content/dataset/train/Bulged_2.jpg  \n",
            "  inflating: /content/dataset/train/Bulged_2.xml  \n",
            "  inflating: /content/dataset/train/Bulged_3.jpg  \n",
            "  inflating: /content/dataset/train/Bulged_3.xml  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED - IMG-20220710-WA0002.jpg  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED - IMG-20220710-WA0002.xml  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED IMG-20220710-WA0003.jpg  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED IMG-20220710-WA0003.xml  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED IMG-20220710-WA0004.jpg  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED IMG-20220710-WA0004.xml  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED IMG-20220710-WA0005.jpg  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED IMG-20220710-WA0005.xml  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED IMG-20220710-WA0006.jpg  \n",
            "  inflating: /content/dataset/train/CONER POST DAMAGES AND DENTED IMG-20220710-WA0006.xml  \n",
            "  inflating: /content/dataset/train/Corner  Cast damage  + DENTED unit CAIU3735731 IMG-20220713-WA0010.jpg  \n",
            "  inflating: /content/dataset/train/Corner  Cast damage  + DENTED unit CAIU3735731 IMG-20220713-WA0010.xml  \n",
            "  inflating: /content/dataset/train/Corner  Cast damage  + DENTED unit CAIU3735731 IMG-20220713-WA0011.jpg  \n",
            "  inflating: /content/dataset/train/Corner  Cast damage  + DENTED unit CAIU3735731 IMG-20220713-WA0011.xml  \n",
            "  inflating: /content/dataset/train/Corner Cast damage unit IMG-20220713-WA0010.jpg  \n",
            "  inflating: /content/dataset/train/Corner Cast damage unit IMG-20220713-WA0010.xml  \n",
            "  inflating: /content/dataset/train/Corner Cast damage unit IMG-20220713-WA0011.jpg  \n",
            "  inflating: /content/dataset/train/Corner Cast damage unit IMG-20220713-WA0011.xml  \n",
            "  inflating: /content/dataset/train/CUT - IMG-20211024-WA0004.jpg  \n",
            "  inflating: /content/dataset/train/CUT - IMG-20211024-WA0004.xml  \n",
            "  inflating: /content/dataset/train/CUT - IMG-20211024-WA0005.jpg  \n",
            "  inflating: /content/dataset/train/CUT - IMG-20211024-WA0005.xml  \n",
            "  inflating: /content/dataset/train/CUT - IMG-20211024-WA0009.jpg  \n",
            "  inflating: /content/dataset/train/CUT - IMG-20211024-WA0009.xml  \n",
            "  inflating: /content/dataset/train/cut 1657964971528.jpg  \n",
            "  inflating: /content/dataset/train/cut 1657964971528.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220626_202553_HDR.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220626_202553_HDR.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_015211_HDR.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_015211_HDR.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_015218_HDR.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_015218_HDR.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_022626_HDR.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_022626_HDR.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_022631_HDR.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_022631_HDR.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_022636_HDR.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG_20220702_022636_HDR.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20211115-WA0000.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20211115-WA0000.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20211115-WA0001.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20211115-WA0001.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20211115-WA0003.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20211115-WA0003.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20211115-WA0004.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20211115-WA0004.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220411-WA0004.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220411-WA0004.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220411-WA0005.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220411-WA0005.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220411-WA0006.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220411-WA0006.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220411-WA0007.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220411-WA0007.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220619-WA0001.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220619-WA0001.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220619-WA0002.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220619-WA0002.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220619-WA0003.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220619-WA0003.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220619-WA0006.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220619-WA0006.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220623-WA0024.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220623-WA0024.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220623-WA0025.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220623-WA0025.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220630-WA0002.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220630-WA0002.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220630-WA0003.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220630-WA0003.xml  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220630-WA0004.jpg  \n",
            "  inflating: /content/dataset/train/CUT IMG-20220630-WA0004.xml  \n",
            "  inflating: /content/dataset/train/cut IMG-20220716-WA0039.jpg  \n",
            "  inflating: /content/dataset/train/cut IMG-20220716-WA0039.xml  \n",
            "  inflating: /content/dataset/train/cut IMG-20220719-WA0035.jpg  \n",
            "  inflating: /content/dataset/train/cut IMG-20220719-WA0035.xml  \n",
            "  inflating: /content/dataset/train/Cut_1.jpg  \n",
            "  inflating: /content/dataset/train/Cut_1.xml  \n",
            "  inflating: /content/dataset/train/Cut_10.jpg  \n",
            "  inflating: /content/dataset/train/Cut_10.xml  \n",
            "  inflating: /content/dataset/train/Cut_2.jpg  \n",
            "  inflating: /content/dataset/train/Cut_2.xml  \n",
            "  inflating: /content/dataset/train/Cut_3.jpg  \n",
            "  inflating: /content/dataset/train/Cut_3.xml  \n",
            "  inflating: /content/dataset/train/Cut_4.jpg  \n",
            "  inflating: /content/dataset/train/Cut_4.xml  \n",
            "  inflating: /content/dataset/train/Cut_5.jpg  \n",
            "  inflating: /content/dataset/train/Cut_5.xml  \n",
            "  inflating: /content/dataset/train/Cut_6.jpg  \n",
            "  inflating: /content/dataset/train/Cut_6.xml  \n",
            "  inflating: /content/dataset/train/Cut_7.jpg  \n",
            "  inflating: /content/dataset/train/Cut_7.xml  \n",
            "  inflating: /content/dataset/train/Cut_8.jpg  \n",
            "  inflating: /content/dataset/train/Cut_8.xml  \n",
            "  inflating: /content/dataset/train/Cut_9.jpg  \n",
            "  inflating: /content/dataset/train/Damage  IMG-20220611-WA0027.jpg  \n",
            "  inflating: /content/dataset/train/Damage  IMG-20220611-WA0027.xml  \n",
            "  inflating: /content/dataset/train/Damage  IMG-20220611-WA0028.jpg  \n",
            "  inflating: /content/dataset/train/Damage  IMG-20220611-WA0028.xml  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095023.jpg  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095023.xml  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095106.jpg  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095106.xml  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095111.jpg  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095111.xml  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095118.jpg  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095118.xml  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095126.jpg  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095126.xml  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095158.jpg  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095158.xml  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095208.jpg  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095208.xml  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095414.jpg  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095414.xml  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095428.jpg  \n",
            "  inflating: /content/dataset/train/DAMAGE UNIT 20220630_095428.xml  \n",
            "  inflating: /content/dataset/train/DENT IMG-20211118-WA0044.jpg  \n",
            "  inflating: /content/dataset/train/DENT IMG-20211118-WA0044.xml  \n",
            "  inflating: /content/dataset/train/DENT IMG-20211118-WA0047.jpg  \n",
            "  inflating: /content/dataset/train/DENT IMG-20211118-WA0047.xml  \n",
            "  inflating: /content/dataset/train/DENT IMG-20220626-WA0004.jpg  \n",
            "  inflating: /content/dataset/train/DENT IMG-20220626-WA0004.xml  \n",
            "  inflating: /content/dataset/train/DENT IMG-20220626-WA0005.jpg  \n",
            "  inflating: /content/dataset/train/DENT IMG-20220626-WA0005.xml  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0020.jpg  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0020.xml  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0021.jpg  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0021.xml  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0022.jpg  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0022.xml  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0023.jpg  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0023.xml  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0024.jpg  \n",
            "  inflating: /content/dataset/train/dent IMG-20220716-WA0024.xml  \n",
            "  inflating: /content/dataset/train/dent WhatsApp Image 2022-07-19 at 2.16.25 PM.jpeg  \n",
            "  inflating: /content/dataset/train/dent WhatsApp Image 2022-07-19 at 2.16.25 PM.xml  \n",
            "  inflating: /content/dataset/train/dent WhatsApp Image 2022-07-19 at 2.18.03 PM.jpeg  \n",
            "  inflating: /content/dataset/train/dent WhatsApp Image 2022-07-19 at 2.18.03 PM.xml  \n",
            "  inflating: /content/dataset/train/DENTED & BULGE OUT IMG-20220719-WA0028.jpg  \n",
            "  inflating: /content/dataset/train/DENTED & BULGE OUT IMG-20220719-WA0028.xml  \n",
            "  inflating: /content/dataset/train/DENTED & BULGE OUT IMG-20220719-WA0036.jpg  \n",
            "  inflating: /content/dataset/train/DENTED & BULGE OUT IMG-20220719-WA0036.xml  \n",
            "  inflating: /content/dataset/train/DENTED & BULGE OUT IMG-20220719-WA0037.jpg  \n",
            "  inflating: /content/dataset/train/DENTED & BULGE OUT IMG-20220719-WA0037.xml  \n",
            "  inflating: /content/dataset/train/DENTED & BULGE OUT IMG-20220719-WA0039.jpg  \n",
            "  inflating: /content/dataset/train/DENTED & BULGE OUT IMG-20220719-WA0039.xml  \n",
            "  inflating: /content/dataset/train/Dented_1.jpg  \n",
            "  inflating: /content/dataset/train/Dented_1.xml  \n",
            "  inflating: /content/dataset/train/Dented_10.jpg  \n",
            "  inflating: /content/dataset/train/Dented_10.xml  \n",
            "  inflating: /content/dataset/train/Dented_11.jpg  \n",
            "  inflating: /content/dataset/train/Dented_11.xml  \n",
            "  inflating: /content/dataset/train/Dented_12.jpg  \n",
            "  inflating: /content/dataset/train/Dented_13.jpg  \n",
            "  inflating: /content/dataset/train/Dented_13.xml  \n",
            "  inflating: /content/dataset/train/Dented_14.jpg  \n",
            "  inflating: /content/dataset/train/Dented_14.xml  \n",
            "  inflating: /content/dataset/train/Dented_15.jpg  \n",
            "  inflating: /content/dataset/train/Dented_15.xml  \n",
            "  inflating: /content/dataset/train/Dented_16.jpg  \n",
            "  inflating: /content/dataset/train/Dented_16.xml  \n",
            "  inflating: /content/dataset/train/Dented_17.jpg  \n",
            "  inflating: /content/dataset/train/Dented_17.xml  \n",
            "  inflating: /content/dataset/train/Dented_18.jpg  \n",
            "  inflating: /content/dataset/train/Dented_19.jpg  \n",
            "  inflating: /content/dataset/train/Dented_2.jpg  \n",
            "  inflating: /content/dataset/train/Dented_2.xml  \n",
            "  inflating: /content/dataset/train/Dented_20.jpg  \n",
            "  inflating: /content/dataset/train/Dented_20.xml  \n",
            "  inflating: /content/dataset/train/Dented_21.jpg  \n",
            "  inflating: /content/dataset/train/Dented_21.xml  \n",
            "  inflating: /content/dataset/train/Dented_22.jpg  \n",
            "  inflating: /content/dataset/train/Dented_22.xml  \n",
            "  inflating: /content/dataset/train/Dented_23.jpg  \n",
            "  inflating: /content/dataset/train/Dented_23.xml  \n",
            "  inflating: /content/dataset/train/Dented_24.jpg  \n",
            "  inflating: /content/dataset/train/Dented_24.xml  \n",
            "  inflating: /content/dataset/train/Dented_25.jpeg  \n",
            "  inflating: /content/dataset/train/Dented_25.xml  \n",
            "  inflating: /content/dataset/train/Dented_26.jpeg  \n",
            "  inflating: /content/dataset/train/Dented_26.xml  \n",
            "  inflating: /content/dataset/train/Dented_27.jpeg  \n",
            "  inflating: /content/dataset/train/Dented_27.xml  \n",
            "  inflating: /content/dataset/train/Dented_28.jpg  \n",
            "  inflating: /content/dataset/train/Dented_28.xml  \n",
            "  inflating: /content/dataset/train/Dented_3.jpg  \n",
            "  inflating: /content/dataset/train/Dented_3.xml  \n",
            "  inflating: /content/dataset/train/Dented_5.jpg  \n",
            "  inflating: /content/dataset/train/Dented_5.xml  \n",
            "  inflating: /content/dataset/train/Dented_6.jpg  \n",
            "  inflating: /content/dataset/train/Dented_7.jpg  \n",
            "  inflating: /content/dataset/train/Dented_7.xml  \n",
            "  inflating: /content/dataset/train/Dented_8.jpg  \n",
            "  inflating: /content/dataset/train/Dented_8.xml  \n",
            "  inflating: /content/dataset/train/Dented_9.jpg  \n",
            "  inflating: /content/dataset/train/Dented_9.xml  \n",
            "  inflating: /content/dataset/train/HOLE IMG_20220711_205739_HDR.jpg  \n",
            "  inflating: /content/dataset/train/HOLE IMG_20220711_205739_HDR.xml  \n",
            "  inflating: /content/dataset/train/HOLE IMG_20220711_205745_HDR.jpg  \n",
            "  inflating: /content/dataset/train/HOLE IMG_20220711_205745_HDR.xml  \n",
            "  inflating: /content/dataset/train/HOLE IMG-20220624-WA0003.jpg  \n",
            "  inflating: /content/dataset/train/HOLE IMG-20220624-WA0003.xml  \n",
            "  inflating: /content/dataset/train/HOLE IMG-20220624-WA0004.jpg  \n",
            "  inflating: /content/dataset/train/HOLE IMG-20220624-WA0004.xml  \n",
            "  inflating: /content/dataset/train/HOLE IMG-20220624-WA0006.jpg  \n",
            "  inflating: /content/dataset/train/HOLE IMG-20220624-WA0006.xml  \n",
            "  inflating: /content/dataset/train/Hole_1.jpg  \n",
            "  inflating: /content/dataset/train/Hole_1.xml  \n",
            "  inflating: /content/dataset/train/Hole_2.jpg  \n",
            "  inflating: /content/dataset/train/Hole_2.xml  \n",
            "  inflating: /content/dataset/train/Hole_3.jpg  \n",
            "  inflating: /content/dataset/train/Hole_3.xml  \n",
            "  inflating: /content/dataset/train/Hole_4.jpg  \n",
            "  inflating: /content/dataset/train/Hole_5.jpg  \n",
            "  inflating: /content/dataset/train/Hole_6.jpg  \n",
            "  inflating: /content/dataset/train/Hole_6.xml  \n",
            "  inflating: /content/dataset/train/IMG_20230117_011825_HDR.jpg  \n",
            "  inflating: /content/dataset/train/IMG_20230117_011825_HDR.xml  \n",
            "  inflating: /content/dataset/train/IMG_20230117_011857_HDR.jpg  \n",
            "  inflating: /content/dataset/train/IMG_20230117_011857_HDR.xml  \n",
            "  inflating: /content/dataset/train/IMG_9566.jpg  \n",
            "  inflating: /content/dataset/train/IMG_9566.xml  \n",
            "  inflating: /content/dataset/train/IMG_9571.jpg  \n",
            "  inflating: /content/dataset/train/IMG_9571.xml  \n",
            "  inflating: /content/dataset/train/IMG_9572.jpg  \n",
            "  inflating: /content/dataset/train/IMG_9572.xml  \n",
            "  inflating: /content/dataset/train/IMG_9573.jpg  \n",
            "  inflating: /content/dataset/train/IMG_9573.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230111-WA0022.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230111-WA0022.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230112-WA0016.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230112-WA0016.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230112-WA0018.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230112-WA0018.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230112-WA0019.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230112-WA0019.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230114-WA0015.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230114-WA0015.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230117-WA0002.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230117-WA0002.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230117-WA0003.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230117-WA0003.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230117-WA0025.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230117-WA0025.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230117-WA0032.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230117-WA0032.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230118-WA0012.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230118-WA0012.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230118-WA0013.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230118-WA0013.xml  \n",
            "  inflating: /content/dataset/train/IMG-20230118-WA0019.jpg  \n",
            "  inflating: /content/dataset/train/IMG-20230118-WA0019.xml  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mANwVYopSP4_",
        "outputId": "a690da32-9655-462a-9393-b73b387fea76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSY1pCDmSVMG",
        "outputId": "56be1874-b857-457e-b90e-5427db4819e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements_1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A31_XF7hSZAm",
        "outputId": "aef84db7-20e9-4199-a355-7db9a7ac48b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xarray==2022.12.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements_1.txt (line 1)) (2022.12.0)\n",
            "Collecting pandas==1.3\n",
            "  Downloading pandas-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.4.0\n",
            "  Downloading tensorflow-2.4.0-cp38-cp38-manylinux2010_x86_64.whl (394.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements_1.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: pymc==4.1.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements_1.txt (line 5)) (4.1.4)\n",
            "Requirement already satisfied: pandas-gbq==0.17.9 in /usr/local/lib/python3.8/dist-packages (from -r requirements_1.txt (line 6)) (0.17.9)\n",
            "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements_1.txt (line 7)) (0.56.4)\n",
            "Requirement already satisfied: google-colab==1.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements_1.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from xarray==2022.12.0->-r requirements_1.txt (line 1)) (1.24.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from xarray==2022.12.0->-r requirements_1.txt (line 1)) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3->-r requirements_1.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3->-r requirements_1.txt (line 2)) (2022.7.1)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.0->-r requirements_1.txt (line 3)) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.0->-r requirements_1.txt (line 3)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.0->-r requirements_1.txt (line 3)) (2.9.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.0->-r requirements_1.txt (line 3)) (1.15.0)\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of xarray to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xarray==2022.12.0\n",
            "  Downloading xarray-2022.12.0-py3-none-any.whl (969 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m970.0/970.0 KB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Cannot install -r requirements_1.txt (line 1), -r requirements_1.txt (line 2) and -r requirements_1.txt (line 3) because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    xarray 2022.12.0 depends on numpy>=1.20\n",
            "    pandas 1.3.0 depends on numpy>=1.17.3\n",
            "    tensorflow 2.4.0 depends on numpy~=1.19.2\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnAWzMe6SZ9k",
        "outputId": "304ef7ef-0f3f-48ca-8d0f-a9ce64e71c74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting absl-py==0.11.0\n",
            "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs==1.4.3\n",
            "  Downloading appdirs-1.4.3-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.6.3)\n",
            "Collecting CacheControl==0.12.6\n",
            "  Downloading CacheControl-0.12.6-py2.py3-none-any.whl (19 kB)\n",
            "Collecting cachetools==4.2.0\n",
            "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
            "Collecting certifi==2019.11.28\n",
            "  Downloading certifi-2019.11.28-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.0/156.0 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.0.4\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama==0.4.3\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Collecting contextlib2==0.6.0\n",
            "  Downloading contextlib2-0.6.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting distlib==0.3.0\n",
            "  Downloading distlib-0.3.0.zip (571 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.0/572.0 KB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting distro==1.4.0\n",
            "  Downloading distro-1.4.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: flatbuffers==1.12 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (1.12)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting google-auth==1.24.0\n",
            "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib==0.4.2\n",
            "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 16)) (0.2.0)\n",
            "Collecting grpcio==1.32.0\n",
            "  Downloading grpcio-1.32.0-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: html5lib==1.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 19)) (1.0.1)\n",
            "Collecting idna==2.8\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipaddr==2.2.0\n",
            "  Downloading ipaddr-2.2.0.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (1.1.2)\n",
            "Collecting lockfile==0.12.2\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting Markdown==3.3.3\n",
            "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.3/96.3 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msgpack==0.6.2\n",
            "  Downloading msgpack-0.6.2.tar.gz (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/119.1 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.19.4\n",
            "  Downloading numpy-1.19.4-cp38-cp38-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib==3.1.0\n",
            "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.4/147.4 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 28)) (3.3.0)\n",
            "Collecting packaging==20.3\n",
            "  Downloading packaging-20.3-py2.py3-none-any.whl (37 kB)\n",
            "Collecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pep517==0.8.2\n",
            "  Downloading pep517-0.8.2-py2.py3-none-any.whl (18 kB)\n",
            "Collecting Pillow==8.0.1\n",
            "  Downloading Pillow-8.0.1-cp38-cp38-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting progress==1.5\n",
            "  Downloading progress-1.5.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf==3.14.0\n",
            "  Downloading protobuf-3.14.0-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 36)) (0.2.8)\n",
            "Collecting pyparsing==2.4.6\n",
            "  Downloading pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.2/227.2 KB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytoml==0.1.21\n",
            "  Downloading pytoml-0.1.21-py2.py3-none-any.whl (8.5 kB)\n",
            "Collecting pytz==2020.4\n",
            "  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 KB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-oauthlib==1.3.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting retrying==1.3.3\n",
            "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rsa==4.6\n",
            "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 45)) (1.15.0)\n",
            "Collecting tensorboard==2.4.0\n",
            "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit==1.7.0\n",
            "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.5/779.5 KB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.4.0\n",
            "  Using cached tensorflow-2.4.0-cp38-cp38-manylinux2010_x86_64.whl (394.8 MB)\n",
            "Collecting tensorflow-estimator==2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 KB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor==1.1.0\n",
            "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions==3.7.4.3\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting urllib3==1.25.8\n",
            "  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 53)) (0.5.1)\n",
            "Requirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 54)) (1.0.1)\n",
            "Collecting wrapt==1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse==1.6.3->-r requirements.txt (line 3)) (0.38.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.8/dist-packages (from google-auth==1.24.0->-r requirements.txt (line 14)) (57.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from pep517==0.8.2->-r requirements.txt (line 31)) (0.10.2)\n",
            "Building wheels for collected packages: distlib, ipaddr, msgpack, progress, retrying, termcolor, wrapt\n",
            "  Building wheel for distlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distlib: filename=distlib-0.3.0-py3-none-any.whl size=340446 sha256=c5e56e1bb180f06a468b060aa839576913cc4ddfe968846311c7c72c2f9d1b8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/4e/d2/a903d4184fb49e4ac06474d65715b129aee13d69f7d227e78e\n",
            "  Building wheel for ipaddr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipaddr: filename=ipaddr-2.2.0-py3-none-any.whl size=18296 sha256=cb6eab38686402347af9f2f3beb69b415d19abe4c05f9c044f0db315016f2db8\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/59/0e/c20fbbd7969a095fa10b79bdde5d9852227f60bdbdd3a90b49\n",
            "  Building wheel for msgpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for msgpack: filename=msgpack-0.6.2-cp38-cp38-linux_x86_64.whl size=341781 sha256=20c933bf5725514a7d7daa5124f15dc76bbef5ac6943209c7457c75faaa53a51\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/f2/04/0d19c10080b996bef17c908a6243e6e65d8da1a4094a3f604d\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.5-py3-none-any.whl size=8087 sha256=af76516ac2bdd39625f08372a6f3b42000cdb4680464c647a0cad487ceaf0677\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/5b/38/115b213dfbf5562108ea22df17c063f6378350205a819795aa\n",
            "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11448 sha256=51e251cd90e89c499e4a6eb3bdb0cc287221b02618f6e36e78d95d95c1fb4361\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/a7/48/0a434133f6d56e878ca511c0e6c38326907c0792f67b476e56\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=d22728a6148663782f58ef336d9d28d7d18ca6ef0ad34618ad3e61c404f422af\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=78574 sha256=28ecbb8940c0a6bb77fb31c4521ff2758db616d3c311d84a859b516a2088eb24\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
            "Successfully built distlib ipaddr msgpack progress retrying termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard-plugin-wit, pytz, pytoml, progress, msgpack, lockfile, ipaddr, distro, distlib, chardet, certifi, appdirs, urllib3, rsa, retrying, python-dateutil, pyparsing, protobuf, Pillow, pep517, oauthlib, numpy, Markdown, idna, grpcio, gast, contextlib2, colorama, cachetools, absl-py, requests, pandas, packaging, h5py, google-auth, requests-oauthlib, CacheControl, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.4.0\n",
            "    Uninstalling typing_extensions-4.4.0:\n",
            "      Successfully uninstalled typing_extensions-4.4.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.2.0\n",
            "    Uninstalling termcolor-2.2.0:\n",
            "      Successfully uninstalled termcolor-2.2.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard-plugin-wit\n",
            "    Found existing installation: tensorboard-plugin-wit 1.8.1\n",
            "    Uninstalling tensorboard-plugin-wit-1.8.1:\n",
            "      Successfully uninstalled tensorboard-plugin-wit-1.8.1\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.7.1\n",
            "    Uninstalling pytz-2022.7.1:\n",
            "      Successfully uninstalled pytz-2022.7.1\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.4\n",
            "    Uninstalling msgpack-1.0.4:\n",
            "      Successfully uninstalled msgpack-1.0.4\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.12.7\n",
            "    Uninstalling certifi-2022.12.7:\n",
            "      Successfully uninstalled certifi-2022.12.7\n",
            "  Attempting uninstall: appdirs\n",
            "    Found existing installation: appdirs 1.4.4\n",
            "    Uninstalling appdirs-1.4.4:\n",
            "      Successfully uninstalled appdirs-1.4.4\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: pep517\n",
            "    Found existing installation: pep517 0.13.0\n",
            "    Uninstalling pep517-0.13.0:\n",
            "      Successfully uninstalled pep517-0.13.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.2.2\n",
            "    Uninstalling oauthlib-3.2.2:\n",
            "      Successfully uninstalled oauthlib-3.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.2\n",
            "    Uninstalling numpy-1.24.2:\n",
            "      Successfully uninstalled numpy-1.24.2\n",
            "  Attempting uninstall: Markdown\n",
            "    Found existing installation: Markdown 3.4.1\n",
            "    Uninstalling Markdown-3.4.1:\n",
            "      Successfully uninstalled Markdown-3.4.1\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.51.1\n",
            "    Uninstalling grpcio-1.51.1:\n",
            "      Successfully uninstalled grpcio-1.51.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: contextlib2\n",
            "    Found existing installation: contextlib2 0.5.5\n",
            "    Uninstalling contextlib2-0.5.5:\n",
            "      Successfully uninstalled contextlib2-0.5.5\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.0\n",
            "    Uninstalling cachetools-5.3.0:\n",
            "      Successfully uninstalled cachetools-5.3.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.0\n",
            "    Uninstalling packaging-23.0:\n",
            "      Successfully uninstalled packaging-23.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.16.0\n",
            "    Uninstalling google-auth-2.16.0:\n",
            "      Successfully uninstalled google-auth-2.16.0\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 1.3.1\n",
            "    Uninstalling requests-oauthlib-1.3.1:\n",
            "      Successfully uninstalled requests-oauthlib-1.3.1\n",
            "  Attempting uninstall: CacheControl\n",
            "    Found existing installation: CacheControl 0.12.11\n",
            "    Uninstalling CacheControl-0.12.11:\n",
            "      Successfully uninstalled CacheControl-0.12.11\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.4 which is incompatible.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.3 which is incompatible.\n",
            "xarray 2022.12.0 requires pandas>=1.3, but you have pandas 1.1.5 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.4 which is incompatible.\n",
            "sqlalchemy 2.0.0 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "pymc 4.1.4 requires cachetools>=4.2.1, but you have cachetools 4.2.0 which is incompatible.\n",
            "pydata-google-auth 1.6.0 requires google-auth<3.0dev,>=1.25.0; python_version >= \"3.6\", but you have google-auth 1.24.0 which is incompatible.\n",
            "pydantic 1.10.4 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "proto-plus 1.22.2 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 3.14.0 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires google-auth>=1.25.0, but you have google-auth 1.24.0 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.4 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.4 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.32.0 which is incompatible.\n",
            "googleapis-common-protos 1.58.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests>=2.25.1, but you have requests 2.22.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-storage 2.7.0 requires google-auth<3.0dev,>=1.25.0, but you have google-auth 1.24.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-core 2.3.2 requires google-auth<3.0dev,>=1.25.0, but you have google-auth 1.24.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.32.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.18.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-api-core 2.11.0 requires google-auth<3.0dev,>=2.14.1, but you have google-auth 1.24.0 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.19.4 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed CacheControl-0.12.6 Markdown-3.3.3 Pillow-8.0.1 absl-py-0.11.0 appdirs-1.4.3 cachetools-4.2.0 certifi-2019.11.28 chardet-3.0.4 colorama-0.4.3 contextlib2-0.6.0 distlib-0.3.0 distro-1.4.0 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 grpcio-1.32.0 h5py-2.10.0 idna-2.8 ipaddr-2.2.0 lockfile-0.12.2 msgpack-0.6.2 numpy-1.19.4 oauthlib-3.1.0 packaging-20.3 pandas-1.1.5 pep517-0.8.2 progress-1.5 protobuf-3.14.0 pyparsing-2.4.6 python-dateutil-2.8.1 pytoml-0.1.21 pytz-2020.4 requests-2.22.0 requests-oauthlib-1.3.0 retrying-1.3.3 rsa-4.6 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.25.8 wrapt-1.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGNj_5KpStl8",
        "outputId": "59c94011-a047-4666-f6e6-eb7b570e500e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwtsoLqCT1iY",
        "outputId": "25293536-f8cf-49a4-ece9-31b778c831f7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 81095, done.\u001b[K\n",
            "remote: Counting objects: 100% (632/632), done.\u001b[K\n",
            "remote: Compressing objects: 100% (305/305), done.\u001b[K\n",
            "remote: Total 81095 (delta 401), reused 530 (delta 324), pack-reused 80463\u001b[K\n",
            "Receiving objects: 100% (81095/81095), 596.12 MiB | 15.76 MiB/s, done.\n",
            "Resolving deltas: 100% (57742/57742), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yw4em9yUFTG",
        "outputId": "9ad458ef-13b8-4b53-af73-021ce176dd9e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.44.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.6.0)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.19.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.3)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.17\n",
            "  Using cached numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.68)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2020.4)\n",
            "Collecting numpy>=1.17\n",
            "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (0.11.0)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Collecting objsize<0.7.0,>=0.6.1\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.5-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio!=1.48.0,<2,>=1.33.1\n",
            "  Downloading grpcio-1.51.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.2/526.2 KB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.14.0)\n",
            "Collecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.30.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.30.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.24.0)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.25.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2019.11.28)\n",
            "Collecting protobuf<4,>3.12.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (20.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Collecting keras\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4,>3.12.2\n",
            "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.3.3)\n",
            "Collecting absl-py>=0.2.2\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.12.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Collecting google-auth<3.0.0dev,>=1.19.0\n",
            "  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696777 sha256=5deea219cfbf59e11c4017d9697ebb95d831aabbb1866399f53bafd68c467ef6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fwd64297/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=4d992bad434d65ba21fc8739fc82cad4f492886ca617d16880a4dcf6a710a4b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=c05cf2ed1c35aaf83cd5bbfcfd27105adc46b0bd4aac3f4e4b57e9a5d5ebc6c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=1c4cf7a145712bd1d68b8bb4eb04ace72289e2eef9a5836946dc5e18e1155a7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=8596874a71e750acb50c7bcea9b2d9bd7ae476d3c039b9508bf814c3b4da8358\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built object-detection avro-python3 dill seqeval docopt\n",
            "Installing collected packages: sentencepiece, py-cpuinfo, flatbuffers, docopt, zstandard, tensorflow_io, tensorflow-estimator, requests, pyyaml, pyparsing, pymongo, protobuf, portalocker, orjson, objsize, numpy, keras, immutabledict, grpcio, fasteners, fastavro, dill, avro-python3, absl-py, tf-slim, tensorflow-model-optimization, sacrebleu, hdfs, google-auth, tensorflow-addons, lvis, apache-beam, tensorboard, seqeval, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.22.0\n",
            "    Uninstalling requests-2.22.0:\n",
            "      Successfully uninstalled requests-2.22.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 2.4.6\n",
            "    Uninstalling pyparsing-2.4.6:\n",
            "      Successfully uninstalled pyparsing-2.4.6\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.14.0\n",
            "    Uninstalling protobuf-3.14.0:\n",
            "      Successfully uninstalled protobuf-3.14.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.4\n",
            "    Uninstalling numpy-1.19.4:\n",
            "      Successfully uninstalled numpy-1.19.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.32.0\n",
            "    Uninstalling grpcio-1.32.0:\n",
            "      Successfully uninstalled grpcio-1.32.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.11.0\n",
            "    Uninstalling absl-py-0.11.0:\n",
            "      Successfully uninstalled absl-py-0.11.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.24.0\n",
            "    Uninstalling google-auth-1.24.0:\n",
            "      Successfully uninstalled google-auth-1.24.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.3 which is incompatible.\n",
            "xarray 2022.12.0 requires pandas>=1.3, but you have pandas 1.1.5 which is incompatible.\n",
            "pymc 4.1.4 requires cachetools>=4.2.1, but you have cachetools 4.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-1.4.0 apache-beam-2.44.0 avro-python3-1.10.2 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.1 fasteners-0.18 flatbuffers-23.1.21 google-auth-2.16.0 grpcio-1.51.1 hdfs-2.7.0 immutabledict-2.2.3 keras-2.11.0 lvis-0.5.3 numpy-1.22.4 object-detection-0.1 objsize-0.6.1 orjson-3.8.5 portalocker-2.7.0 protobuf-3.19.6 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.2 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-addons-0.19.0 tensorflow-estimator-2.11.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.30.0 tf-models-official-2.11.3 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade packaging\n",
        "!pip install --upgrade cachetools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpGZtHtuUgO9",
        "outputId": "21c47188-9fbb-4c54-a8a6-dcaed817f851"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.1.5)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2020.4)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.3 which is incompatible.\n",
            "pymc 4.1.4 requires cachetools>=4.2.1, but you have cachetools 4.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (20.3)\n",
            "Collecting packaging\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: packaging\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 20.3\n",
            "    Uninstalling packaging-20.3:\n",
            "      Successfully uninstalled packaging-20.3\n",
            "Successfully installed packaging-23.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.8/dist-packages (4.2.0)\n",
            "Collecting cachetools\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Installing collected packages: cachetools\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 4.2.0\n",
            "    Uninstalling cachetools-4.2.0:\n",
            "      Successfully uninstalled cachetools-4.2.0\n",
            "Successfully installed cachetools-5.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1RV8E0wUkRd",
        "outputId": "9c73e32f-1a71-43c6-b949-6df2b3b13ca9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.44.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.11.3)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.30.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.22.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.19.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.3)\n",
            "Requirement already satisfied: tensorflow-text~=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: tensorflow~=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.97)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.68)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2020.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.19.0)\n",
            "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.18)\n",
            "Requirement already satisfied: cloudpickle~=2.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7.1)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.1)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.28.2)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.8.5)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.30.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.8/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.25.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2019.11.28)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.1.21)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.12.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696777 sha256=9197dee1f3108e0a8ca21215af3e47f392236fcadac58cd70ab74b88469b29fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-um11qmed/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Attempting uninstall: object-detection\n",
            "    Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xarray\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es7ts3-QUvFU",
        "outputId": "661550c7-4f72-4a72-9d6c-adfb75170f4c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.8/dist-packages (2022.12.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from xarray) (23.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from xarray) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.8/dist-packages (from xarray) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3->xarray) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3->xarray) (2020.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3->xarray) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPAII0JYUxcl",
        "outputId": "d37d2722-056a-4efc-ad45-b88325477139"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.44.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.11.3)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.30.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.22.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.68)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.97)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.19.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Requirement already satisfied: tensorflow-text~=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: tensorflow~=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2020.4)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.28.2)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.19.0)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.8.5)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.18)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.13.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.30.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.30.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.8/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2019.11.28)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.25.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.1.21)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.12.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696777 sha256=63b56c4f4df77f2deed558117af77a862c0c2980891365825761fd78882eed3b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gy48csz3/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Attempting uninstall: object-detection\n",
            "    Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the model builder test\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwUWPClHU2-F",
        "outputId": "d2529a80-1c6c-443b-cd60-1d2756033320"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-06 15:23:41.572971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-06 15:23:42.588394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-06 15:23:42.588547: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-06 15:23:42.588566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Running tests under Python 3.8.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2023-02-06 15:23:51.550754: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0206 15:23:51.973325 140577594420288 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.37s\n",
            "I0206 15:23:52.423754 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.37s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.05s\n",
            "I0206 15:23:53.474215 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.48s\n",
            "I0206 15:23:53.957746 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.48s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n",
            "I0206 15:23:54.391220 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.87s\n",
            "I0206 15:23:57.266282 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.87s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0206 15:23:57.274745 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.26s\n",
            "I0206 15:23:57.533932 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "I0206 15:23:57.561355 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I0206 15:23:57.588796 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.17s\n",
            "I0206 15:23:57.763469 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "I0206 15:23:57.876155 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "I0206 15:23:57.988665 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "I0206 15:23:58.097933 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "I0206 15:23:58.202354 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0206 15:23:58.232820 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0206 15:23:58.423410 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0206 15:23:58.423566 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I0206 15:23:58.423631 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
            "I0206 15:23:58.425884 140577594420288 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 15:23:58.451876 140577594420288 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 15:23:58.452001 140577594420288 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 15:23:58.524808 140577594420288 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 15:23:58.524974 140577594420288 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 15:23:58.706021 140577594420288 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 15:23:58.706174 140577594420288 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0206 15:23:58.892463 140577594420288 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0206 15:23:58.892628 140577594420288 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0206 15:23:59.152713 140577594420288 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0206 15:23:59.152901 140577594420288 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0206 15:23:59.423259 140577594420288 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0206 15:23:59.423464 140577594420288 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0206 15:23:59.784209 140577594420288 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0206 15:23:59.784380 140577594420288 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0206 15:23:59.871524 140577594420288 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0206 15:23:59.913486 140577594420288 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 15:23:59.961079 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0206 15:23:59.961225 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I0206 15:23:59.961292 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
            "I0206 15:23:59.962830 140577594420288 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 15:23:59.979833 140577594420288 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 15:23:59.979964 140577594420288 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 15:24:00.117846 140577594420288 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 15:24:00.118025 140577594420288 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 15:24:00.374755 140577594420288 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 15:24:00.374943 140577594420288 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0206 15:24:00.644623 140577594420288 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0206 15:24:00.644802 140577594420288 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0206 15:24:00.998346 140577594420288 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0206 15:24:00.998569 140577594420288 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0206 15:24:01.344783 140577594420288 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0206 15:24:01.344987 140577594420288 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0206 15:24:01.776660 140577594420288 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0206 15:24:01.776837 140577594420288 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0206 15:24:01.963512 140577594420288 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0206 15:24:01.996999 140577594420288 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 15:24:02.057621 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0206 15:24:02.057785 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I0206 15:24:02.057870 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
            "I0206 15:24:02.059559 140577594420288 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 15:24:02.077463 140577594420288 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 15:24:02.077583 140577594420288 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 15:24:02.390275 140577594420288 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 15:24:02.390449 140577594420288 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 15:24:02.658331 140577594420288 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 15:24:02.658502 140577594420288 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0206 15:24:02.935947 140577594420288 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0206 15:24:02.936113 140577594420288 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0206 15:24:03.287077 140577594420288 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0206 15:24:03.287268 140577594420288 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0206 15:24:03.651472 140577594420288 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0206 15:24:03.651647 140577594420288 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0206 15:24:04.104823 140577594420288 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0206 15:24:04.105046 140577594420288 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0206 15:24:04.290505 140577594420288 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0206 15:24:04.330580 140577594420288 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 15:24:04.388990 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0206 15:24:04.389161 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I0206 15:24:04.389238 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
            "I0206 15:24:04.390835 140577594420288 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0206 15:24:04.411268 140577594420288 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0206 15:24:04.411431 140577594420288 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 15:24:04.563581 140577594420288 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 15:24:04.563748 140577594420288 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0206 15:24:04.826338 140577594420288 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0206 15:24:04.826516 140577594420288 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0206 15:24:05.082170 140577594420288 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0206 15:24:05.082342 140577594420288 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0206 15:24:05.523152 140577594420288 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0206 15:24:05.523328 140577594420288 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0206 15:24:06.012784 140577594420288 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0206 15:24:06.012991 140577594420288 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0206 15:24:06.540975 140577594420288 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0206 15:24:06.541145 140577594420288 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0206 15:24:06.729215 140577594420288 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0206 15:24:06.768957 140577594420288 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 15:24:06.830704 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0206 15:24:06.830886 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I0206 15:24:06.830962 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0206 15:24:06.832627 140577594420288 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0206 15:24:06.852282 140577594420288 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0206 15:24:06.852414 140577594420288 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 15:24:06.996442 140577594420288 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 15:24:06.996607 140577594420288 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0206 15:24:07.325364 140577594420288 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0206 15:24:07.325541 140577594420288 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0206 15:24:07.677996 140577594420288 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0206 15:24:07.678156 140577594420288 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0206 15:24:08.359942 140577594420288 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0206 15:24:08.360136 140577594420288 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0206 15:24:09.352458 140577594420288 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0206 15:24:09.352658 140577594420288 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0206 15:24:10.312693 140577594420288 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0206 15:24:10.312904 140577594420288 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0206 15:24:10.592178 140577594420288 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0206 15:24:10.651414 140577594420288 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 15:24:10.782592 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0206 15:24:10.782820 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I0206 15:24:10.782938 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0206 15:24:10.785819 140577594420288 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0206 15:24:10.813747 140577594420288 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0206 15:24:10.814150 140577594420288 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 15:24:11.107914 140577594420288 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 15:24:11.108122 140577594420288 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0206 15:24:11.751724 140577594420288 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0206 15:24:11.751964 140577594420288 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0206 15:24:12.404227 140577594420288 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0206 15:24:12.404458 140577594420288 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0206 15:24:13.314363 140577594420288 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0206 15:24:13.314593 140577594420288 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0206 15:24:14.231367 140577594420288 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0206 15:24:14.231573 140577594420288 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0206 15:24:15.386586 140577594420288 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0206 15:24:15.386796 140577594420288 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0206 15:24:15.803893 140577594420288 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0206 15:24:15.863132 140577594420288 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 15:24:16.014201 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0206 15:24:16.014427 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0206 15:24:16.014537 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0206 15:24:16.017356 140577594420288 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0206 15:24:16.046792 140577594420288 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0206 15:24:16.046963 140577594420288 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0206 15:24:16.364686 140577594420288 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0206 15:24:16.364982 140577594420288 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0206 15:24:17.140213 140577594420288 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0206 15:24:17.140424 140577594420288 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0206 15:24:17.902392 140577594420288 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0206 15:24:17.902595 140577594420288 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0206 15:24:19.250298 140577594420288 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0206 15:24:19.250515 140577594420288 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0206 15:24:20.288727 140577594420288 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0206 15:24:20.288961 140577594420288 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0206 15:24:21.493168 140577594420288 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0206 15:24:21.493339 140577594420288 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0206 15:24:21.757534 140577594420288 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0206 15:24:21.794004 140577594420288 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 15:24:21.880647 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0206 15:24:21.880810 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0206 15:24:21.880899 140577594420288 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0206 15:24:21.882534 140577594420288 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0206 15:24:21.902826 140577594420288 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0206 15:24:21.902973 140577594420288 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0206 15:24:22.191805 140577594420288 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0206 15:24:22.191999 140577594420288 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0206 15:24:22.773322 140577594420288 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0206 15:24:22.773502 140577594420288 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0206 15:24:23.360914 140577594420288 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0206 15:24:23.361075 140577594420288 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0206 15:24:24.204468 140577594420288 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0206 15:24:24.204639 140577594420288 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0206 15:24:25.063113 140577594420288 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0206 15:24:25.063286 140577594420288 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0206 15:24:26.168443 140577594420288 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0206 15:24:26.168623 140577594420288 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0206 15:24:26.527209 140577594420288 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0206 15:24:26.565300 140577594420288 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.68s\n",
            "I0206 15:24:26.912258 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.68s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0206 15:24:26.936956 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0206 15:24:26.938706 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0206 15:24:26.939189 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0206 15:24:26.940522 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0206 15:24:26.941678 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0206 15:24:26.942082 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0206 15:24:26.942954 140577594420288 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 36.889s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4wRG1xFVDl_",
        "outputId": "332fdc4a-b705-4998-eb37-4a74f332dadb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_PDx_C6VFMk",
        "outputId": "a5917811-27a4-4a5b-952f-45de218b61b8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train data:\n",
        "!python generate_tfrecord.py -x /content/dataset/train -l /content/dataset/labelmap.pbtxt -o /content/dataset/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python generate_tfrecord.py -x /content/dataset/test -l /content/dataset/labelmap.pbtxt -o /content/dataset/test.record"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqo7rQp7VKrF",
        "outputId": "61461d3d-d7ef-4486-8d7b-d12e693e2f80"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"generate_tfrecord.py\", line 172, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"generate_tfrecord.py\", line 162, in main\n",
            "    tf_example = create_tf_example(group, path)\n",
            "  File \"generate_tfrecord.py\", line 136, in create_tf_example\n",
            "    classes.append(class_text_to_int(row['class']))\n",
            "  File \"generate_tfrecord.py\", line 105, in class_text_to_int\n",
            "    return label_map_dict[row_label]\n",
            "KeyError: 'dent'\n",
            "Successfully created the TFRecord file: /content/dataset/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_tfrecord.py -x /content/dataset/train -l /content/dataset/labelmap.pbtxt -o /content/dataset/train.record\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ef3jXc2ZYDA",
        "outputId": "bd484d7d-d613-4bae-8ab6-0e049c1c749c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: /content/dataset/train.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "!tar -xvf efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "!rm efficientdet_d0_coco17_tpu-32.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Lk0Re8ajQU",
        "outputId": "151c26c4-cb31-45c1-ad8b-cc1497211301"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2023-02-06 16:01:40--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.68.128, 2404:6800:4003:c02::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.68.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30736482 (29M) [application/x-tar]\n",
            "Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz’\n",
            "\n",
            "efficientdet_d0_coc 100%[===================>]  29.31M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-02-06 16:01:40 (250 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz’ saved [30736482/30736482]\n",
            "\n",
            "efficientdet_d0_coco17_tpu-32/\n",
            "efficientdet_d0_coco17_tpu-32/checkpoint/\n",
            "efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0.data-00000-of-00001\n",
            "efficientdet_d0_coco17_tpu-32/checkpoint/checkpoint\n",
            "efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0.index\n",
            "efficientdet_d0_coco17_tpu-32/pipeline.config\n",
            "efficientdet_d0_coco17_tpu-32/saved_model/\n",
            "efficientdet_d0_coco17_tpu-32/saved_model/saved_model.pb\n",
            "efficientdet_d0_coco17_tpu-32/saved_model/assets/\n",
            "efficientdet_d0_coco17_tpu-32/saved_model/variables/\n",
            "efficientdet_d0_coco17_tpu-32/saved_model/variables/variables.data-00000-of-00001\n",
            "efficientdet_d0_coco17_tpu-32/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
        "!mv ssd_efficientdet_d0_512x512_coco17_tpu-8.config efficientdet_d0_coco17_tpu-32.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM-IlO9vdjvO",
        "outputId": "bd3f61ca-d875-4638-e3e4-f9f2bfe44fe7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-06 16:01:48--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4630 (4.5K) [text/plain]\n",
            "Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’\n",
            "\n",
            "ssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-06 16:01:49 (67.5 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’ saved [4630/4630]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "learning_rate_base: 8e-3\n",
        "warmup_learning_rate: 0.0001\n",
        "batch_size = 8 #16\n",
        "num_steps = 1000 #1500\n",
        "num_eval_steps = 500\n",
        "\n",
        "train_record_path = '/content/dataset/train.record'\n",
        "test_record_path = '/content/dataset/test.record'\n",
        "model_dir = '/content/training/'\n",
        "labelmap_path = '/content/dataset/labelmap.pbtxt'\n",
        "\n",
        "pipeline_config_path = 'efficientdet_d0_coco17_tpu-32.config'\n",
        "fine_tune_checkpoint = '/content/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'\n",
        "fine_tune_checkpoint_type= 'detection'"
      ],
      "metadata": {
        "id": "sO3JyvAWdlsr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open(pipeline_config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open(pipeline_config_path, 'w') as f:\n",
        "\n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"', \n",
        "  'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
        "  \n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint),\n",
        "                  config)\n",
        "  # Set fine_tune_checkpoint type (classification or detection)\n",
        "  config = re.sub('fine_tune_checkpoint_type: \".*?\"',\n",
        "                  'fine_tune_checkpoint_type: \"{}\"'.format(fine_tune_checkpoint_type),\n",
        "                  config)\n",
        "  # Set batch size.\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(batch_size), config)\n",
        "  \n",
        "  # # Set learning rate base\n",
        "  # config = re.sub('learning_rate_base: \".*?\"',\n",
        "  #                 'learning_rate_base: \"{}\"'.format(learning_rate_base),\n",
        "  #                 config)\n",
        "  \n",
        "  # # Set warmup learning rate.\n",
        "  # config = re.sub('warmup_learning_rate: [0-9]+',\n",
        "  #                 'warmup_learning_rate: {}'.format(warmup_learning_rate), config)\n",
        "  \n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
        "  \n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
        "  \n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(num_classes), config)\n",
        "\n",
        "  \n",
        "  f.write(config)"
      ],
      "metadata": {
        "id": "MgbgIvcFd6dS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py --pipeline_config_path={pipeline_config_path} --model_dir=training --alsologtostderr"
      ],
      "metadata": {
        "id": "hg7KrcLzd-Qx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}